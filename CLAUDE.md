# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a capstone project building an AI-powered healthcare information system that combines:
- **RAG (Retrieval-Augmented Generation)**: Document-based knowledge retrieval using AWS Bedrock Knowledge Base
- **MCP (Model Context Protocol)**: Structured database queries through safe, scoped tools
- **Chat UI**: User interface for querying both documents and live data

The system allows healthcare professionals to ask questions that are answered using both clinical documentation (via RAG) and live patient data (via MCP tools), all powered by AWS Bedrock (Claude and Titan models).

## Architecture

### High-Level Components

1. **Backend (Python)**: MCP server hosting database query tools
2. **Frontend**: Chat UI (provided, will be deployed to ECS)
3. **Database**: Milvus vector database for embeddings
4. **AWS Services**:
   - **Bedrock**: AI models (Claude for responses, Titan Embeddings for vectors)
   - **Bedrock Knowledge Base**: Stores document embeddings for semantic search
   - **S3**: Document storage for RAG ingestion
   - **ECS/Fargate**: Container orchestration for deployment
   - **Lambda**: Triggers for RAG ingestion pipeline

### Key Concepts

- **Vector Embeddings**: Numeric representations of text that capture semantic meaning, generated by Titan Embeddings
- **RAG Pipeline**: Documents → S3 → Lambda → Chunking → Titan Embeddings → Vector DB → Semantic Search
- **MCP Tools**: Pre-defined, safe functions that allow AI to query structured data without arbitrary SQL access
- **Bedrock KB**: Searchable document store that retrieves relevant chunks and provides citations

### Development Environment

The project uses Docker for local development with three services:
- `capstone-backend`: Python backend (port 8000)
- `capstone-frontend`: Nginx serving static frontend (port 3000)
- `capstone-database`: Milvus vector database (ports 19530/19121)

All services communicate via the `capstone` bridge network.

## Docker Commands

### Starting Services

From the `docker/` directory:
```bash
docker compose up -d
```

Or use Docker Desktop GUI.

### Stopping Services

```bash
docker compose down
```

### Checking Running Containers

```bash
docker container ps
```

### Testing Dependencies Inside Container

```bash
docker container exec -it capstone-backend bash
pip install new_library_name
exit
```

**IMPORTANT**: Changes inside containers are temporary. Do not commit from inside containers.

### Dependency Management

- Backend dependencies are in `backend/requirements.txt`
- Only Adriean Lemoine should update `requirements.txt` and rebuild containers
- Log dependency needs instead of modifying the file directly

## Project Structure

```
.
├── backend/              # Python backend (MCP server, main.py entry point)
│   ├── Dockerfile
│   └── requirements.txt  # Python dependencies (numpy, scipy, pandas, pathlib2)
├── docker/              # Docker Compose configuration
│   └── docker-compose.yml
├── docs/                # Planning and technical documentation
│   ├── spec.md                      # Project specification (placeholder)
│   ├── guide_tech_stack_concepts.md # AWS Bedrock, RAG, MCP, ECS concepts
│   ├── guide_docker.md              # Docker workflow (optional for now)
│   ├── playbook_workflow.md         # Team workflow (placeholder)
│   ├── playbook_planning.md         # Project phases and roles
│   └── playbook_milestones.md       # Development milestones
└── README.md            # Points to playbook_workflow.md
```

**Note**: `frontend/` and `database/` directories will be created as development progresses.

## Development Phases

The project follows a phased approach (see `docs/playbook_milestones.md` for details):

1. **RAG Foundation**: Set up S3, Bedrock KB, document ingestion, semantic search
2. **Chat UI**: Deploy provided UI to ECS, connect to Bedrock KB
3. **MCP Server**: Build Python server with database query functions
4. **MCP Protocol Integration**: Wrap DB functions as MCP tools with schemas
5. **RAG + MCP Integration**: Combine document and database queries
6. **Hardening**: Scaling, observability, deployment polish

## Team Roles

- **Infra**: Environment design and maintenance (Adriean - primary)
- **RAG**: Document ingestion and retrieval tuning
- **MCP**: Database tool implementation
- **Integration**: Component coordination (Adriean - secondary)
- **Documentation**: Technical docs and guides

## MCP Tools (Planned)

Potential clinical query tools to implement:
- Patient demographics/search
- Medications per patient
- Lab results per patient
- Encounters/visits history
- Patients missing checkups
- Aggregate statistics by condition
- Medication conflict detection
- Recent prescriptions or changes

Each tool:
- Has specific, scoped inputs (no arbitrary SQL)
- Returns structured, predictable JSON output
- Is read-only (no destructive operations)
- Provides a safety boundary between AI and database

## Key Documentation

- `docs/guide_tech_stack_concepts.md`: Comprehensive explanations of AWS Bedrock, RAG, vector embeddings, MCP, ECS/Fargate
- `docs/playbook_planning.md`: Detailed phase breakdown with role assignments
- `docs/playbook_milestones.md`: Why each milestone comes in this order

## Important Notes

- This is an early-stage project with skeleton infrastructure
- No actual backend code exists yet (only Dockerfile and requirements.txt)
- Frontend and database directories referenced in docker-compose.yml don't exist yet
- Focus is on AWS serverless architecture (Fargate, Lambda, Bedrock)
- All team members should read `docs/guide_tech_stack_concepts.md` to align on terminology

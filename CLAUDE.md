# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Special Instructions

**"Add context" Command**: When any team member uses the phrase "Add context" followed by information, automatically add that information to this CLAUDE.md file in the appropriate section (or create a new section if needed). This allows quick updates to project context without explicit file editing requests.

**"Reobtain context" Command**: When the phrase "Reobtain context" is used, re-reference the updated CLAUDE.md to obtain an up-to-date understanding of project context.

## Project Overview

This is a capstone project building an AI-powered healthcare information system that combines:
- **RAG (Retrieval-Augmented Generation)**: Document-based knowledge retrieval using AWS Bedrock Knowledge Base
- **MCP (Model Context Protocol)**: Structured database queries through safe, scoped tools
- **Chat UI (React + TypeScript)**: User interface for querying both documents and live data

The system allows healthcare professionals to ask questions that are answered using both clinical documentation (via RAG) and live patient data (via MCP tools), all powered by AWS Bedrock (Claude and Titan models).

## Architecture

### High-Level Components

1. **Chat UI (React + TypeScript)**: User interface for querying documents and patient data
2. **LLM Orchestrator (Python)**: Routes queries between RAG and MCP, handles Bedrock API calls
3. **MCP Server (Python)**: Hosts database query tools for structured patient data access
4. **RAG Pipeline**: Document ingestion and retrieval (Lambda functions, S3 triggers)
5. **Data Stores**:
   - **SQL Database**: Patient data (demographics, meds, labs, encounters)
   - **Bedrock Knowledge Base**: Clinical document embeddings and semantic search
6. **AWS Services**:
   - **Bedrock**: AI models (Claude for responses, Titan Embeddings for vectors)
   - **Bedrock Knowledge Base**: Vector storage and semantic search for RAG
   - **S3**: Document storage for RAG ingestion
   - **RDS**: SQL database (PostgreSQL) for patient data
   - **ECS/Fargate**: Container orchestration for deployment
   - **Lambda**: Triggers for RAG ingestion pipeline

### Key Architecture Decisions

- **Vector Storage**: AWS Bedrock Knowledge Base (not Milvus) - fully managed, integrated with Bedrock
- **Patient Data Storage**: SQL database (local PostgreSQL container for dev, RDS for production)
- **No separate vector database needed**: Bedrock KB handles all embedding storage and retrieval

### Key Concepts

- **Vector Embeddings**: Numeric representations of text that capture semantic meaning, generated by Titan Embeddings
- **RAG Pipeline**: Documents → S3 → Lambda → Chunking → Titan Embeddings → Bedrock KB → Semantic Search
- **MCP Tools**: Pre-defined, safe functions that allow AI to query structured data without arbitrary SQL access
- **Bedrock KB**: Fully managed searchable document store that retrieves relevant chunks and provides citations

### Development Environment

The project uses Docker for local development with containerized services:
- MCP Server (Python)
- Chat UI (Nginx/React)
- SQL Database (PostgreSQL)

All services communicate via Docker bridge network. Infrastructure setup is managed by the Infra lead.

## Docker Commands

### Starting Services

From the `docker/` directory:
```bash
docker compose up -d
```

Or use Docker Desktop GUI.

### Stopping Services

```bash
docker compose down
```

### Checking Running Containers

```bash
docker container ps
```

### Testing Dependencies Inside Container

```bash
docker container exec -it capstone-backend bash
pip install new_library_name
exit
```

**IMPORTANT**: Changes inside containers are temporary. Do not commit from inside containers.

### Dependency Management

- Python dependencies are managed in each component's `requirements.txt`
- Only Adriean Lemoine should update requirements files and rebuild containers
- Log dependency needs instead of modifying files directly
- Use environment variables for configuration (connection strings, API keys, etc.)

## Project Structure

The repository is organized by system component (aligned with Jira epics):

```
.
├── chat-ui/              # Frontend Chat Interface (Epic 1)
│   ├── Dockerfile
│   ├── src/
│   └── (React/Vue application code)
├── llm-orchestrator/     # LLM Orchestrator (Epic 3)
│   ├── Dockerfile
│   ├── src/
│   └── (Query routing, Bedrock API integration)
├── mcp-server/           # MCP Server and Database Setup (Epic 4)
│   ├── Dockerfile
│   ├── requirements.txt
│   ├── main.py
│   └── tools/            # MCP tool implementations
├── rag-pipeline/         # RAG / Knowledge Base Setup (Epic 6)
│   ├── lambda/           # Lambda function code
│   └── scripts/          # Ingestion utilities
├── infra/                # AWS Infrastructure and Deployment (Epic 2)
│   ├── docker/
│   │   └── docker-compose.yml  # Local development environment
│   ├── terraform/        # Infrastructure as Code
│   └── github/
│       └── workflows/    # CI/CD pipelines
├── docs/                 # Documentation
│   ├── workflows/        # Per-component workflow guides
│   │   ├── workflow_chat_ui.md
│   │   ├── workflow_llm_orchestrator.md
│   │   ├── workflow_mcp_server.md
│   │   └── workflow_rag_pipeline.md
│   ├── guides/           # Technical concept guides
│   └── playbooks/        # Project planning and phases
├── CLAUDE.md             # AI assistant context
└── README.md
```

**Note**: This structure separates concerns by component rather than traditional frontend/backend split.

## Development Phases

The project follows a phased approach (see `docs/playbook_milestones.md` for details):

1. **RAG Foundation**: Set up S3, Bedrock KB, document ingestion, semantic search
2. **Chat UI**: Build React + TypeScript chat interface from scratch, deploy to ECS
3. **MCP Server**: Build Python server with database query functions
4. **MCP Protocol Integration**: Wrap DB functions as MCP tools with schemas
5. **RAG + MCP Integration**: Combine document and database queries
6. **Hardening**: Scaling, observability, deployment polish

## Team Roles

- **Infra**: Environment design and maintenance (Adriean Lemoine)
- **Frontend**: React + TypeScript chat UI development (Paul)
- **Orchestrator**: LLM routing and Bedrock API integration (Adam)
- **MCP**: Database tool implementation and MCP server (Sebastian)
- **RAG**: Document ingestion and retrieval tuning (Hunter)
- **Integration**: Component coordination (Adriean - secondary role)
- **Documentation**: Technical docs and guides (shared by all)

## File Naming Convention

- **Standard files**: Use lowercase_separated_by_underscores (snake_case) for all files
- **Exceptions**: README.md and CLAUDE.md use UPPERCASE
- **Examples**:
  - ✅ `workflow_chat_ui.md`
  - ✅ `guide_tech_stack_concepts.md`
  - ✅ `claude_code_cheatsheet.md`
  - ❌ `WorkflowChatUI.md`
  - ❌ `TECH_STACK_GUIDE.md`

## Version Control Guidelines

- **Temporary Files**: Never commit files to the repo that start with `temp_` in their file name. These are working files only and should remain local.

## Code Organization Principles

- **Avoid Megafiles**: Keep code files focused and reasonably sized. Break large files into smaller, logical modules.
- **Modular Architecture**: Write clean, modular code with clear separation of concerns.
- **Purpose**: Modular code is easier to build, test, troubleshoot, and maintain. Large monolithic files become difficult to navigate and debug.

## Project Epics

The project is organized into 6 Jira epics that represent parallel workstreams:

1. **Frontend Chat Interface** - User interface for querying documents and live data
2. **AWS Infrastructure and Deployment** - ECS/Fargate, networking, IAM, deployment pipeline
3. **LLM Orchestrator** - Logic to route queries between RAG and MCP, interact with Bedrock
4. **MCP Server and Database Setup** - Python MCP server with database query tools, SQL database setup
5. **DSS Team / External Dependencies** - Coordination with external teams and systems
6. **RAG / Knowledge Base Setup** - S3, Bedrock Knowledge Base, document ingestion, embeddings

These epics complement the linear development phases outlined above by showing how work is organized across the team.

## MCP Tools (Planned)

Potential clinical query tools to implement:
- Patient demographics/search
- Medications per patient
- Lab results per patient
- Encounters/visits history
- Patients missing checkups
- Aggregate statistics by condition
- Medication conflict detection
- Recent prescriptions or changes

Each tool:
- Has specific, scoped inputs (no arbitrary SQL)
- Returns structured, predictable JSON output
- Is read-only (no destructive operations)
- Provides a safety boundary between AI and database

## Key Documentation

**Quick Reference:**
- `docs/claude_code_cheatsheet.md`: How to interact with Claude Code efficiently

**Technical Guides:**
- `docs/guides/guide_tech_stack_concepts.md`: AWS Bedrock, RAG, vector embeddings, MCP, ECS/Fargate
- `docs/guides/guide_docker.md`: Docker workflow and container management

**Project Planning:**
- `docs/playbooks/playbook_planning.md`: Detailed phase breakdown with role assignments
- `docs/playbooks/playbook_milestones.md`: Why each milestone comes in this order
- `docs/playbooks/playbook_workflow.md`: Team workflow and collaboration

**Component Workflows (Per-Epic):**
- `docs/workflows/workflow_chat_ui.md`: Frontend development workflow
- `docs/workflows/workflow_llm_orchestrator.md`: LLM routing logic workflow
- `docs/workflows/workflow_mcp_server.md`: MCP tool development workflow
- `docs/workflows/workflow_rag_pipeline.md`: RAG ingestion workflow

## Important Notes

- This is an early-stage project with skeleton infrastructure
- Component directories will be created as development progresses
- Focus is on AWS serverless architecture (Fargate, Lambda, Bedrock)
- All team members should read `docs/guides/guide_tech_stack_concepts.md` to align on terminology
- Each component has its own workflow documentation in `docs/workflows/`
- Infrastructure setup (Docker, AWS resources) is managed by the Infra lead
